Sobre mim


Meu nome é Kauã Kirk, sou estudante de Sistemas de Informação na UFOP. Embora minha experiência com dados ainda seja breve, já utilizei bibliotecas como o Pandas para filtrar informações e construir gráficos.
Meus principais hobbies incluem jogos online, assistir séries e acompanhar/jogar futebol.

Sprint 1:--------------------------------

Sprint 2: 
1. Manipulação e Análise de Dados com Pandas
Eu aprimorei minhas habilidades com a biblioteca Pandas para manipulação e análise de dados em Python:

Leitura e Inspeção de Dados:

Aprendi a carregar datasets em um DataFrame usando pd.read_csv() e a inspecionar os dados com métodos como .head(), .info(), e .describe() para entender a estrutura e o conteúdo do dataset.
Tratamento de Dados:

Tratei valores ausentes utilizando .fillna() e .dropna().
Identifiquei duplicatas com .duplicated() e as removi com .drop_duplicates().
Corrigi inconsistências nos dados e renomeei colunas para facilitar a análise e melhorar a organização.
Transformações de Colunas:

Criei colunas calculadas, como receita e ticket médio, para enriquecer as análises.
Realizei conversões de tipos de dados sempre que necessário para adequar os valores às análises.
Agrupamento e Estatísticas:

Usei o método .groupby() para realizar análises agregadas por categorias, como:
Vendas por dia da semana.
Receita por mês.
Visualizações:

Aprendi a gerar gráficos usando as bibliotecas Matplotlib e Seaborn para apresentar insights visuais, como:
Gráficos de barras para vendas por loja, estado ou marca.
Gráficos de linha para mostrar a evolução de leads e vendas ao longo do tempo.
Filtros e Segmentação:

Utilizei condições (DataFrame[condição]) para filtrar dados específicos, como vendas realizadas em um período determinado.
2. Manipulação e Análise de Dados com SQL
Eu adquiri habilidades importantes para trabalhar com dados em bancos relacionais usando SQL:

Consultas Básicas e Agrupamentos:

Utilizei SELECT para selecionar colunas específicas.
Apliquei GROUP BY para agrupar dados e gerar insights, como:
Quantidade de vendas por estado.
Leads (visitas) e vendas por mês.
Funções Agregadas:

Usei funções como COUNT(), SUM(), e AVG() para:
Contar vendas realizadas.
Calcular receitas totais e médias.
Joins e Combinações de Tabelas:

Dominei o uso de LEFT JOIN para unir tabelas e cruzar informações, conectando dados de clientes, produtos e funil de vendas para análises mais completas.
Filtragem e Intervalos de Datas:

Utilizei cláusulas WHERE para aplicar filtros específicos, como vendas realizadas em períodos determinados (por exemplo, agosto de 2021).
Ordenação e Limitação de Resultados:

Organizei os resultados com ORDER BY e utilizei LIMIT para exibir apenas os mais relevantes, como os estados ou marcas com mais vendas.

Sprint 3:

Entropia e Classes
Entropia: Mede a impureza de um conjunto de dados.
Entropia = 0: Todas as instâncias pertencem à mesma classe.
Entropia = 1: Todas as classes possuem o mesmo número de instâncias.
Aprendizado Baseado em Grupo
Combinar vários classificadores pode superar a performance de um único, ajustando hiperparâmetros adequados.
Random Forest: Induz várias árvores de decisão, combina os resultados para aumentar a precisão.
Classificação Baseada em Instância
Encontra a instância mais semelhante utilizando medidas como a distância euclidiana.
KNN (K-Nearest Neighbors): Algoritmo popular que classifica baseado nos vizinhos mais próximos.
K-Means: Algoritmo de agrupamento (clustering) para separar dados em clusters.
Regras de Associação
Apriori: Se um conjunto de itens é frequente, todos os subconjuntos dele também são frequentes.
Engenharia de Atributos
Pré-processamento de Dados:
Tratar valores nulos substituindo pela média, moda, ou criando uma nova classe.
PCA (Análise de Componentes Principais): Reduz a dimensionalidade criando novos atributos sintéticos.
Seleção de Características: Identificar as mais importantes para o modelo.
Avaliação e Custo de Modelos
Intervalo de confiança: Avalia a robustez dos resultados.
Custo de erros:
Falso positivo: Perda financeira.
Falso negativo: Perda de oportunidade.
Clusters
Determinar se os clusters encontrados realmente existem ou são artefatos do modelo.
Classificação Multilabel
Classificar instâncias que podem pertencer a várias categorias simultaneamente.
Exemplo: "Pode chover" e "Posso jogar bola".
Métricas:
Exact Match: Todos os rótulos corretos.
Hamming Loss: Quanto mais próximo de 0, melhor.
Classes Desbalanceadas
Soluções:
Coletar dados balanceados.
Gerar dados artificialmente.
AutoML e Tuning
Automatização de tarefas como seleção de modelos, otimização de hiperparâmetros e avaliação.
Redes Neurais
Inspiradas nos cérebros de seres vivos, compostas por:
Perceptron: Camadas de entrada com pesos, funções de ativação e saída.
Deep Learning: Redes com várias camadas ocultas para problemas complexos.
Taxa de aprendizado: Não pode ser muito alta ou baixa para garantir a convergência.
Técnicas Avançadas
Reconhecimento de Imagens:
Convolução, Max Pooling, Flattening, Fully Connected Layers.
LSTM (Long Short-Term Memory): Redes recorrentes para lembrar informações de longo prazo.
Autoencoders: Redes para aprender representações compactas dos dados.
Machine Learning Explicável
Tornar modelos mais compreensíveis, mesmo que isso possa impactar a performance.
Tipos de modelos:
Caixa preta (Black Box): Difícil de interpretar.
Caixa branca (White Box): Fácil de entender.
Funções monotônicas: Modelos que seguem um único sentido lógico.
Processamento de Linguagem Natural (PLN)
Área focada em treinar modelos para compreender e gerar linguagem natural.

worlrd embedding
large languuage models
fine tunning
hugging face
open ai
detecção de anomalias: não existem regras gerais, dependo do contexto
z-score
técnicas de ml: local outilers fator, isolation forest,one class svm
series temporais: moving average







https://github.com/user-attachments/assets/f86bddf7-d18b-4858-8e86-f54be93352cc





