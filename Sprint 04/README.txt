# ğŸ“˜ **Curso Python e SageMaker: De A-Z**
Bem-vindo ao repositÃ³rio do curso **Python e SageMaker**! Este repositÃ³rio Ã© uma coleÃ§Ã£o de projetos que abrangem tÃ©cnicas fundamentais e avanÃ§adas de Machine Learning e anÃ¡lise de dados, organizados em duas seÃ§Ãµes principais: **Python** e **SageMaker**.

---

## ğŸ”— **SumÃ¡rio**
1. [Curso de Python de A-Z](#python-de-a-z)  
   1.1 [RegressÃ£o Linear](#regressÃ£o-linear)  
   1.2 [Algoritmo Apriori](#algoritmo-apriori)  
   1.3 [K-Means e Agrupamentos](#k-means-e-agrupamentos)  
   1.4 [ReduÃ§Ã£o de Dimensionalidade](#reduÃ§Ã£o-de-dimensionalidade)  
   1.5 [DetecÃ§Ã£o de Outliers](#detecÃ§Ã£o-de-outliers)  
2. [Curso de SageMaker](#curso-de-sagemaker)  
   2.1 [Bike Random Cut](#bike-random-cut)  
   2.2 [Bikes DeepAR](#bikes-deepar)  
   2.3 [RegressÃ£o Linear - Censo](#regressÃ£o-linear-censo)  
   2.4 [RegressÃ£o Linear - Casas](#regressÃ£o-linear-casas)  
   2.5 [PCA e Agrupamento](#pca-e-agrupamento)  
   2.6 [XGBoost](#xgboost)  

---

## ğŸ **Python de A-Z**

### ğŸ“Š **1. RegressÃ£o Linear ([RL.ipynb](RL.ipynb))**
**Objetivo:** Estudar e implementar a regressÃ£o linear para prever variÃ¡veis contÃ­nuas.  
**Principais aprendizados:**  
- Conceito de regressÃ£o linear simples e mÃºltipla.  
- Uso do `scikit-learn` para ajuste de modelos.  
- MÃ©tricas como RÂ² e MSE para avaliaÃ§Ã£o de performance.  
- ImportÃ¢ncia da visualizaÃ§Ã£o na interpretaÃ§Ã£o de relaÃ§Ãµes.

---

### ğŸ›’ **2. Algoritmo Apriori ([Apriori.ipynb](Apriori.ipynb))**  
**Objetivo:** Identificar padrÃµes frequentes em bases de dados transacionais.  
**Principais aprendizados:**  
- AplicaÃ§Ã£o do algoritmo Apriori para regras de associaÃ§Ã£o.  
- MÃ©tricas como suporte, confianÃ§a e lift.  
- PreparaÃ§Ã£o e limpeza de dados para mineraÃ§Ã£o eficiente.

---

### ğŸ“ˆ **3. K-Means e Agrupamentos ([kmeans_e_agrupamentos.ipynb](kmeans_e_agrupamentos.ipynb))**  
**Objetivo:** Implementar agrupamento nÃ£o supervisionado usando K-Means.  
**Principais aprendizados:**  
- MÃ©todo do cotovelo para definir o nÃºmero ideal de clusters.  
- VisualizaÃ§Ã£o 2D para anÃ¡lise de separaÃ§Ã£o dos grupos.  
- Impacto da inicializaÃ§Ã£o aleatÃ³ria nos resultados.

---

### ğŸ“‰ **4. ReduÃ§Ã£o de Dimensionalidade ([reducaodedados.ipynb](reducaodedados.ipynb))**  
**Objetivo:** Reduzir variÃ¡veis mantendo informaÃ§Ãµes relevantes com PCA.  
**Principais aprendizados:**  
- AvaliaÃ§Ã£o de variÃ¢ncia explicada para validar a reduÃ§Ã£o.  
- BenefÃ­cios em processamento e visualizaÃ§Ã£o.

---

### âš  **5. DetecÃ§Ã£o de Outliers ([outliers.ipynb](outliers.ipynb))**  
**Objetivo:** Identificar e tratar outliers para dados mais confiÃ¡veis.  
**Principais aprendizados:**  
- MÃ©todos estatÃ­sticos como IQR e z-score.  
- VisualizaÃ§Ã£o com boxplots e histogramas.  
- DecisÃµes estratÃ©gicas para remover ou ajustar outliers.

---

## â˜ï¸ **Curso de SageMaker**

### ğŸ›µ **1. Bike Random Cut ([bike-random-cut.ipynb](bike-random-cut.ipynb))**  
**Objetivo:** Prever padrÃµes relacionados a bicicletas usando particionamento aleatÃ³rio.  
**Principais aprendizados:**  
- ExploraÃ§Ã£o de dados sazonais e temporais.  
- ImportÃ¢ncia da anÃ¡lise exploratÃ³ria.  

---

### ğŸ”® **2. Bikes DeepAR ([bikes-deepar.ipynb](bikes-deepar.ipynb))**  
**Objetivo:** Prever sÃ©ries temporais com o modelo DeepAR.  
**Principais aprendizados:**  
- ConfiguraÃ§Ã£o e treinamento do DeepAR no SageMaker.  
- MÃ©tricas como RMSE e MAE para validaÃ§Ã£o.

---

### ğŸ“Š **3. RegressÃ£o Linear - Censo ([linear-leaner-census.ipynb](linear-leaner-census.ipynb))**  
**Objetivo:** PrevisÃ£o socioeconÃ´mica com regressÃ£o linear.  
**Principais aprendizados:**  
- InterpretaÃ§Ã£o de coeficientes no contexto do censo.

---

### ğŸ¡ **4. RegressÃ£o Linear - Casas ([linear-leaner-house.ipynb](linear-leaner-house.ipynb))**  
**Objetivo:** Prever preÃ§os de casas com variÃ¡veis categÃ³ricas.  
**Principais aprendizados:**  
- CodificaÃ§Ã£o one-hot e impacto de variÃ¡veis no preÃ§o.  

---

### ğŸ”„ **5. PCA e Agrupamento ([pca-agrupamento.ipynb](pca-agrupamento.ipynb))**  
**Objetivo:** Reduzir dimensÃµes e agrupar dados similares.  
**Principais aprendizados:**  
- PCA para dimensionalidade e K-Means para agrupamentos.

---

### ğŸ† **6. XGBoost ([xgboost.ipynb](xgboost.ipynb))**  
**Objetivo:** Modelos avanÃ§ados para classificaÃ§Ã£o e regressÃ£o.  
**Principais aprendizados:**  
- Tunagem de hiperparÃ¢metros e validaÃ§Ã£o cruzada.  
- SHAP para avaliaÃ§Ã£o do impacto de features.



